{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trace Upstream Script \n",
    "## Version 2: Directly create upstream trib feature classes \n",
    "Kernel: Python 2\n",
    "\n",
    "Developed by: Curtis Fang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set GDB directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# arcpy.env.workspace='P:\\GIS\\Projects\\LARiver_Watershed_Projects\\General\\Shapefiles\\Subwatersheds\\SubWSTributary.gdb'\n",
    "arcpy.env.workspace='Input\\LosPen\\CC_With Downstream_IDs\\output.gdb'\n",
    "arcpy.env.overwriteOutput = True\n",
    "# input_data='lac_SubWSCatchment_LARWSClip'\n",
    "input_data='DownIDCat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import input feature class as a pandas dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arcpy.conversion.TableToExcel(Input_Table=input_data,\n",
    "                              Output_Excel_File='Output/input.xls'\n",
    "                             )\n",
    "df = pd.read_excel('output/input.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'OBJECTID_1', u'Watershed', u'Final_SWID', u'Shape_Leng', u'Sub_ID',\n",
       "       u'ObjectID', u'Sub_ID_1', u'Dwn_Sub_ID', u'Shape_Length', u'Shape_Area',\n",
       "       u'Sub_ID_s', u'Dwn_Sub_ID_s'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_cols=df.columns\n",
    "orig_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set target downstream catchment and catchment ID columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID_list = [\n",
    "'s4012352145'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_col='Sub_ID_s'\n",
    "ds_col='Dwn_Sub_ID_s'\n",
    "for target_ID in ID_list:\n",
    "    # Define output variables\n",
    "    temp_input=\"_temp_input_\"+target_ID\n",
    "    temp_input_xls='Output/'+temp_input+'.xls'\n",
    "    table_gdb='a'+target_ID+'_upstream'\n",
    "    table_csv=filename = 'Output/'+table_gdb+'.csv'\n",
    "    fc_output='_upstream_'+target_ID\n",
    "\n",
    "    # Trace upstream\n",
    "    _neighbors = df[df[ds_col] == target_ID]\n",
    "    upstream = _neighbors\n",
    "    while not _neighbors.empty:\n",
    "        _neighbors = df[df[ds_col].isin(_neighbors[id_col])]\n",
    "#         print(_neighbors.shape)\n",
    "        upstream = upstream.append(_neighbors, ignore_index=True)\n",
    "#         print(upstream.shape)\n",
    "    #Comment out the line below if one does not want to include the catchment itself\n",
    "    upstream=upstream.append(df[df[id_col]==target_ID],ignore_index=True)\n",
    "    \n",
    "    exc_cols=orig_cols.difference([id_col])\n",
    "    upstream = upstream.drop(exc_cols,1)\n",
    "    \n",
    "    upstream.to_csv(table_csv,index=False)\n",
    "    arcpy.conversion.TableToTable(table_csv,\n",
    "                                 arcpy.env.workspace,\n",
    "                                table_gdb)\n",
    "    \n",
    "    #Create a temp duplicate shapefile in prep for join field - avoid modifying the original input\n",
    "    arcpy.conversion.FeatureClassToFeatureClass(input_data, \n",
    "                                            arcpy.env.workspace, \n",
    "                                            temp_input)\n",
    "    \n",
    "    arcpy.management.JoinField(in_data=temp_input,\n",
    "                          in_field=id_col,\n",
    "                          join_table= table_gdb,\n",
    "                          join_field=id_col)\n",
    "    \n",
    "    expression = id_col+'_1 IS NOT NULL' #Furture improvement: Avoid hard coding the epxression\n",
    "    arcpy.conversion.FeatureClassToFeatureClass(temp_input, \n",
    "                                            arcpy.env.workspace, \n",
    "                                            fc_output,\n",
    "                                           expression)\n",
    "    arcpy.management.Delete(temp_input)\n",
    "    arcpy.management.DeleteField(fc_output,id_col+'_1')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define output variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_input=\"_temp_input_\"+target_ID\n",
    "temp_input_xls='Output/'+temp_input+'.xls'\n",
    "table_gdb='a'+target_ID+'_upstream'\n",
    "table_csv=filename = 'Output/'+table_gdb+'.csv'\n",
    "fc_output='upstream_'+target_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace upstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_neighbors = df[df[ds_col] == target_ID]\n",
    "upstream = _neighbors\n",
    "while not _neighbors.empty:\n",
    "    _neighbors = df[df[ds_col].isin(_neighbors[id_col])]\n",
    "    upstream = upstream.append(_neighbors, ignore_index=True)\n",
    "#Comment out the line below if one does not want to include the catchment itself\n",
    "upstream=upstream.append(df[df[id_col]==target_ID],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exc_cols=orig_cols.difference([id_col])\n",
    "upstream = upstream.drop(exc_cols,1)\n",
    "upstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upstream.to_csv(table_csv,index=False)\n",
    "arcpy.conversion.TableToTable(table_csv,\n",
    "                             arcpy.env.workspace,\n",
    "                            table_gdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create a temp duplicate shapefile in prep for join field - avoid modifying the original input\n",
    "arcpy.conversion.FeatureClassToFeatureClass(input_data, \n",
    "                                            arcpy.env.workspace, \n",
    "                                            temp_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arcpy.management.JoinField(in_data=temp_input,\n",
    "                          in_field=id_col,\n",
    "                          join_table= table_gdb,\n",
    "                          join_field=id_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check join result\n",
    "arcpy.conversion.TableToExcel(Input_Table=temp_input,Output_Excel_File=temp_input_xls)\n",
    "df3 = pd.read_excel(temp_input_xls)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expression = id_col+'_2018 IS NOT NULL' #Furture improvement: Avoid hard coding the epxression\n",
    "arcpy.conversion.FeatureClassToFeatureClass(temp_input, \n",
    "                                            arcpy.env.workspace, \n",
    "                                            fc_output,\n",
    "                                           expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#if run into already exist error, run this block\n",
    "#arcpy.management.Delete(fc_output)\n",
    "# arcpy.env.overwriteOutput = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up temp files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arcpy.management.Delete(temp_input)\n",
    "arcpy.management.DeleteField(fc_output,id_col+'_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
